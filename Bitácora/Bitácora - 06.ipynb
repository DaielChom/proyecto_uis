{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitacora - 06\n",
    "\n",
    "#### 16 - Feb - 18:\n",
    "\"Señoras y caballeros mi saludos mis repseto co el permiso de uds voy a cantar unos verbos.\" Las cosas Se tornaron algo extraño pero a la vez no creo que cambie nada. La reunion de raul nos dejo impactados, una gran noticia la verdad, raul va a renunciar, ya no hay muhco que hacer, teniamos dos opciones o seguir trabajando con el por skype o buscar a otro profesor para hacer proyecto de grado con él, sin dudarlo todos queremos seguir con raul y la verdad si quisiera trabajar con el, espero no surga nada raro y el man no nos deje botados, pero pues confiar en el por ahora a ver que tal, seguire el consejo de @Jez y hare una prueba por un tiempoa ver como me va, pero bueno en otras noticias, lo que me antañe y es que de las dudas a hablar con él de la bitacora anterior, me dijo que dejara el trabajo de secretaria, que perder el tiempo buscando un archivo lo pelaba, que usara los kml a los uqe tenia acceso y ahi se hace algo, es decir si encuentro un kml de las victimas o de seguridad usarlo, que si lo encuentro a nivel nacional pues no pasa nada usarlo a nivel nacional o departamental que no hay afan. y yo quede como :O ese homrbe siempre piensa en las ideas que uno no piensa jajajajajaja es un bueno cucho pa que. Entoncs eso hare, entre todas las paginas donde puedo obtener kml, osea si los puedo descargar vere cual escoger, eso si tengo que enviar un correo a fabio y raul para ver que hacer en la aux, que tambien me tienen sin trabajo en eso, osea estoy como que hheeee y ahora que?. Entoncs la cuestion queda asi.\n",
    "##### Tarea:\n",
    "* Seleccionar las paginas donde puedo descargar los kml facilmente.\n",
    "* Escoger el KML que mas me llame la atencion en trabajar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 19 - Feb - 18:\n",
    "\"Y me sigo molestando por ella, no se ya que sera, aunque creo que si es normal en mi, recuerdi lo de laura tambien fue bastante tiempo, aunq tmabien amistades com la de jez y erika y sacaron la rabia, la de pili me dolio reguero y aun hoy en dia de vez en cuando me achicopalo por eso\" No se si ya haya escrito pero la reunion salio mas X. no recordaba la vbitacora 6. La cuestion es que no hice nada el fin de semana y hoy empezare la seleccion de KML, sigo pensando si meterle mano al json, por ahora vere mejor los kmls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mandar correo con las fechas,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20 - Feb - 18:\n",
    "Cambio nuevamente. O bueno, organizo ideas, por que estaba echo bolas, ya estaba dispuesto a cambiar de proyecto cuando no habia dado todo por luchar, me deje un poco influenciar y desde jeffer hasta jez, pasando con todos los uqe hable, tienen razon aun puedo ponerme hacer los mapas, seria algo complicado y canson pero lo puedo hacer, es trabajo de secretaria si, pero es por algo que realmente quiero hacer, incluso puedo buscar el mapa de estratos en pdf de otras ciudades hacer el mapa y con eso testiar, incluso jez me hizo pensar mientras estoy entranando o probando algo, puedo ir haciendo los otros mapas, incluso podria ser algo como de dia programacion y de noche adelanto mapas, sera engorrozo, pero dedicarme a hacer otra cosa desde casi 0 no quiero, no puedo quedarme sin haber luchado o estar inconforme por que no me dieron algo asi facilito, donde esta el daniel insistente y fastidioso, haceindo mapas hp, del afan y las ocsas borre el README pero no importa se puede volver a restaurar o algo asi, no hay afan, se pueden sacar los archivos de temp, o puede que no, y si hare eso, aprender react tendra que esperar un rato y me dedicare a hacer mapas en las noches, mañana tengo la sustentacion de wilson asi que tampoco es que vaya a aprovehar mucho el dia de mañana, y aun tengo que hablar con fabio y seguir pedaliando, reitero, gracias jeffer, gracias jez, gracias aron y angelica, el ceo y rueda, tellez y ahi a medio velandia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 22 - Feb - 18:\n",
    "Hoy me reuni de nuevo con raul y hable del proyecyo le dije que iba a ahcer el mapa y pues dijo que si que rela que lo hiciera y que despues lo publicara y que bueno que le hiciera quiero aprovechara poner esto \n",
    "![licencia](./img/mapas_bogota_licencia.png)\n",
    "![licencia](./img/mapas_bogota_licencia_02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedo modificar, obivamente debo publicarlo pero lo que estoy haceindo no es ilegal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Reunion 2 - Mar - 18:\n",
    "Raulito estaba como rarito hoy, no se que pero lo note un tris que no era él mismo. Y respecto al tabjajo de grado voy bien, bastante bien, me adelante un poco, a lo que tenia pensado qeu estaba haciendo. Primero, antes de la reunion que acabo de tener con él tenia unas cuantas dudas.\n",
    "\n",
    "##### Dudas\n",
    "* moestratle el dataset sin etiquetar\n",
    "* ,mostrat pero dataset\n",
    "* como seria la etiquetacion\n",
    "* explicarle si seguir ocn ihistogramas o q\n",
    "* como seria la etiquetacion\n",
    "* mas mapas\n",
    "* como afectarian los colores?\n",
    "* mas ciudades?\n",
    "* mas zooms?\n",
    "\n",
    "Y varias de estas dudas eran por que estaba pensando en trabajar con clasificacion, pero por x motivo alparcer y ahora, y mejor para mi, voy a trabjar es con segmentacion, lo que me da a pensar sobre la calidad del mapa que tengo, pero es complicado por que para volverlo a hacer y esta vez de buena manera como que no, podria trabajar asi, ajj la madre, podria trabajar en las noches en la elaboracion de ese mapa y sus 40k casitas por que esa parte de segmentacion si requiere un mejor trabajo en el mapa, creo que trataré de ahcer eso en las noches voy a ver, mientras tambien debo descargar mas imagenes de zoom, y a la vez probar alguna red neuronal o algo sobre segmentacion, eso si me toca consultar a ver que encuentro, la cuestion es como que hacer un tutorial de segmentacion y luego hacer una codigo que comapre ambas imagenes la real con la que se predijo en la seccmentacion, tambien debo adelantar cositas de los mapas extras. y pues segun las fechas voy bien pues ya tengo el dataset, solo es hacer un tutorial de segmentacion con lo que tengo, aunque ueno aun me falta arreglar unas cosas del dataset, como borrar las imagenes que estan grises y eso entoncs las tareas quedan asi.\n",
    "\n",
    "###### Tarea.\n",
    "* Terminar de Arreglar Dataset.\n",
    "* **Hacer mapa de estratos de calidad** --> **DUDA PARA DESPUES** --> dado que ese kml lo hice pensando en clasificacion mas que en segementacion\n",
    "* Hacer tutorial de Segmentacion - Buscando si se pueden ingresar varios canales (mapas) y ver si requiere un tamaño de imagen especifico.\n",
    "* **Descargar mas zooms**\n",
    "* **Hacer mapas extra**\n",
    "* hacer algoritmo para comparar la imagen real y la prediccion\n",
    "* Decidir train y test, de una manera un tanto geografico, es decir que no sea muy aleatorio dado que si dosimagenes muy cercanas entre si quedan una en train y la otra en test, se podria estar sesgando, entoncs toca como que encontrar una manera de dividir las imagenes en test y train, aunque eso podria haberlo echo con las imagnes mas grandes que tenia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Lunes 09 - Abr - 18:\n",
    "A partir de hoy creo que ya me podre dedicar a mi proyecto, adelante arto de la auxiliatura y tambien bastante del Diplomado, solo queda que Duvan me responda el correo, si esta noche no me ha respondido le envio otro correo, la cuestion es que podre dedciarme al proyecto y sera completamente hoy en sacar el dataser, nuevamente. Debo eliminar unos archivos para no procesar tantos, asi que eliminare las siguientes imagenes.\n",
    "\n",
    "##### TEST:\n",
    "* 17 : 1-1, 3-3\n",
    "* 18: 1-1, 1-2, 1-3, 2-1, 2-2, 3-1, 3-5, 4-4, 4-5, 5-3, 5-4, 5-5\n",
    "* 19: 1-1, ,1-2, 1-3. 1-4, 1-5, 1-6, 1-7, 1 -10, 2-1, 2-2, 2-3, 2-4, 2-5, 2-6, 3-1, 3-2, 3-3, 3-4, 4-1, 4-2, 4-3, 4-4, 5-10, 6-1, 6-2, 5-1, 5-2, 6-8, 6-9, 6-10, 7-1, 7-2, 7-7, 7-8, 7-9, 7-10, 8-7, 8-8, 8-9, 8-10, 9-5, 9-6, 9-7, 9-8, 9-9, 9-10, 10-2, 10-3, 10-4, 10-5, 10-6, 10-7, 10-8, 10-9, 10-10\n",
    "* 20: 1-1, 1-2, 1-3,1-4,1-5,1-6,1-7,1-8,1-9,1-10,1-11,1-15,1-16, 2-1,2-2,2-3,2-4,2-5,2-6,2-7,2-8,2-9,2-10,2-11,2-15,2-16, 3-1,3-2,3-3,3-4,3-5,3-6,3-7,3-8,3-9,3-10,3-11, 3-16, 4-1,4-2,4-3,4-4,4-5,4-6,4-7, 4-10, 5-1, 5-2, 5-3, 5-4, 5-5, 5-6, 5-7, 6-1, 6-2, 6-3, 6-4, 6-5, 6-6, 6-15, 7-1, 7-2, 7-3, 7-4, 7-5, 7-15, 7-16, 8-1, 8-2, 8-3, 8-4, 8-14, 8-15, 8-16, 9-1, 9-2, 9-3, 9-4, 9-12, 9-13, 9-14, 9-15, 9-16, 10-1, 10-2, 10-3, 10-4, 10-12, 10-13, 10-14, 10-15, 10-16, 11-1, 11-2, 11-3, 11-4, 11-11, 11-12, 11-13, 11-14, 11-15, 11-16, 12-1, 12-2, 12-3, 12-10, 12-11, 12-12, 12-13, 12-14, 12-15, 12-16, 13-2, 13-3, 13-9, 13-10, 13-11, 13-12, 13-13, 13-14, 13-15, 13-16, 14-3, 14-7, 14-8, 14-9, 14-10, 14-11, 14-12, 14-13, 14-14, 14-15, 14-16, 15-5, 15-6, 15-7, 15-8, 15-9, 15-10, 15-11, 15-12, 15-13, 15-14, 15-15, 15-16, 15-3, 16-3, 16-4, 16-5, 16-6, 16-7, 16-8, 16-9, 16-10, 16-11, 16-12, 16-13, 16-14, 16-15, 16-16\n",
    "* 21: 1-1, 1-2, 1-3, 1-4, 1-5, 1-6, 1-7, 1-8, 1-9, 1-10, 1-11, 1-12, 1-13, 1-14, 1-15, 1-16, 1-17, 1-18, 1-22, 1-23, 1-24, 1-25, 2-1, 2-2, 2-3, 2-4, 2-5, 2-6, 2-7, 2-8, 2-9, 2-10, 2-11, 2-12, 2-13, 2-14, 2-15, 2-16, 2-17, 2-22, 2-23, 2-24, 2-25, 3-1, 3-2, 3-3, 3-4, 3-5, 3-6, 3-7, 3-8, 3-9, 3-10, 3-11, 3-12, 3-13, 3-14, 3-15, 3-16, 3-17, 3-23, 3-24, 3-25\n",
    "4-1, 4-2, 4-3, 4-4, 4-5, 4-6, 4-7, 4-8, 4-9, 4-10, 4-11, 4-12, 4-13, 4-14, 4-15, 4-16, 4-17, 4-23, 4-24, 4-25, 5-1, 5-2,5-3, 5-4, 5-5, 5-6, 5-7, 5-8, 5-9, 5-10, 5-11, 5-12, 5-13, 5-14, 5-15, 5-16, 5-25, 6-1, 6-2, 6-3, 6-4, 6-5, 6-6, 6-7, 6-8, 6-9, 6-10, 6-11, 6-12, 6-15, 6-16, 7-1, 7-2, 7-3, 7-4, 7-5, 7-6, 7-7, 7-8, 7-9, 7-10, 7-11, 7-12, 7-16, 8-1, 8-2, 8-3, 8-4, 8-5, 8-6, 8-7, 8-8, 8-9, 8-10, 8-11, 8-12, 9-1, 9-2, 9-3, 9-4, 9-5, 9-6, 9-7, 9-8, 9-9, 9-10, 9-11, 9-12, 9-23, 9-24, 10-1, 10-2, 10-3, 10-4, 10-5, 10-6, 10-7, 10-8, 10-9, 10-10, 10-23, 10-24, 10-25, 11-1, 11-2, 11-3, 11-4, 11-5, 11-6, 11-7, 11-22, 11-23, 11-24, 11-25, 12-1, 12-2, 12-3, 12-4, 12-5, 12-6, 12-21, 12-22, 12-23, 12-24, 12-25, 13-1, 13-2, 13-3, 13-4, 13-5, 13-6, 13-19, 13-20, 13-21, 13-22, 13-23, 13-24, 13-25, 14-1, 14-2, 14-3, 14-4, 14-5, 14-6, 14-18, 14-19, 14-20, 14-21, 14-22, 14-23, 14-24, 14-25, 15-1, 15-2, 15-3, 15-4, 15-5, 15-6, 15-18, 15-19, 15-20, 15-21, 15-22, 15-23, 15-24, 15-25, 16-1, 16-2, 16-3, 16-4,16-5, 16-6, 16-16, 16-17, 16-18, 16-19, 16-20, 16-21, 16-22, 16-23, 16-24, 16-25, 17-1, 17-2, 17-3, 17-4, 17-5, 17-6, 17-16, 17-17, 17-18, 17-19, 17-20, 17-21, 17-22, 17-23, 17-24, 17-25, 18-1, 18-2, 18-3, 18-4, 18-5, 18-6, 18-16, 18-17, 18-18, 18-19, 18-20, 18-21, 18-22, 18-23, 18-24, 18-25, 19-1, 19-2, 19-3, 19-4, 19-5, 19-15, 19-16, 19-17, 19-18, 19-19, 19-20, 19-21, 19-22, 19-23, 19-24, 19-25, 20-3, 20-4, 20-5, 20-13, 20-14, 20-15, 20-16, 20-17, 20-18, 20-19, 20-20, 20-21, 20-22, 20-23, 20-24, 20-25, 21-4, 21-5, 21-11, 21-12, 21-13, 21-14, 21-15, 21-16, 21-17,21-18, 21-19, 21-20, 21-21, 21-22, 21-23, 21-24, 21-25, 22-4,22-9, 22-10, 22-11, 22-12, 22-13, 22-14, 22-15, 22-16, 22-17, 22-18, 22-19, 22-20, 22-21, 22-22, 22-23, 22-24, 22-25, 23-4, 23-7, 23-8, 23-9, 23-10, 23-11, 23-12, 23-13, 23-14, 23-15, 23-16, 23-17, 23-18, 23-19, 23-20, 23-21, 23-22, 23-23, 23-24, 23-25, 24-1,24-3, 24-4. 24-5, 24-6, 24-7, 24-8, 24-9, 24-10, 24-11, 24-12, 24-13, 24-14, 24-15, 24-16, 24-17, 24-18, 24-19, 24-20, 24-21, 24-22, 24-23, 24, 24-25, 25-1, 25-4, 25-5, 25-6, 25-7, 25-8, 25-9, 25-10, 25-11, 25-12, 25-13, 25-14, 25-15, 25-16, 25-17, 25-18, 25-19, 25-20, 25-21, 25-22, 25-23, 25-24, 25-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: no se puede borrar '../proyecto_dev/data/dataset/test/layer_economic/21/zoom_layer_21_3-254-1.jpg': No existe el archivo o el directorio\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN:\n",
    "* 17: [\"1-1\", \"3-3\"]\n",
    "* 18: 1-1, 1-2, 2-1, 2-2, 3-1, 4-5, 5-3, 5-4, 5-5\n",
    "* 19: 1-1, 1-2, 1-3, 1-4, 1-5, 1-9, 1-10, 2-1, 2-2, 2-3, 2-4, 2-5, 2-10, 3-1, 3-2, 3-3, 3-4, 3-9, 4-1, 4-2, 4-3, 4-4, 5-1, 5-2, 5-3, 6-1, 6-2, 6-3, 7-1, 7-8, 7-9, 7-10, 8-6, 8-7, 8-8, 8-9,8-10, 9-5, 9-6, 9-7, 9-8, 9-9, 9-10, 10-5, 10-6, 10-7, 10-8, 10-9, 10-10\n",
    "* 20: 1-1, 1-2, 1-3, 1-4, 1-5, 1-6, 1-7, 1-8, 1-9, 1-11, 1-14, 1-15, 1-16, 2-1, 2-2, 2-3, 2-4, 2-5, 2-6, 2-7, 2-8, 2-9, 2-14, 2-15, 2-16, 3-1, 3-2, 3-3, 3-4, 3-5, 3-6, 3-7, 3-8, 3-15, 3-16, 4-1, 4-2, 4-3, 4-4, 4-5, 4-6, 4-7, 4-8, 4-14, 4-15, 4-16, 5-1, 5-2, 5-3, 5-4, 5-5, 5-6, 5-7, 5-13, 5-15, 6-1, 6-2, 6-3, 6-4, 6-5, 6-6, 7-1, 7-2, 7-3, 7-4, 7-5, 7-6, 7-16, 8-1, 8-2, 8-3, 8-4, 8-5, 8-6, 8-16, 9-1, 9-2, 9-3, 9-4, 9-5, 10-1, 10-2, 10-3, 10-4, 10-14, 11-1, 11-2, 11-3, 11-13, 11-14, 11-15, 11-16, 12-1, 12-9, 12-10, 12-11, 12-12, 12-13, 12-14, 12-15, 12-16, 13-8, 13-9, 13-10, 13-11, 13-12, 13-13, 13-14, 13-15, 13-16, 14-8, 14-9, 14-10, 14-11, 14-12, 14-13, 14-14, 14-15, 14-16, 15-7, 15-8, 15-9, 15-10, 15-11, 15-12, 15-13, 15-14, 15-15, 15-16, 16-1, 16-4, 16-5, 16-7, 16-8, 16-8, 16-9, 16-10, 16-11, 16-12, 16-13, 16-14, 16-15, 16-16\n",
    "* 21: 1-1, 1-2,1-3, 1-4, 1-5, 1-6, 1-7, 1-8, 1-9, 1-10, 1-11, 1-12, 1-13, 1-14, 1-15, 1-16,1-17,1-18, 1-20, 1-21, 1-22, 1-23, 1-24, 1-25, 2-1, 2-2, 2-3, 2-4, 2-5, 2-6, 2-7, 2-8, 2-9, 2-10, 2-11, 2-12, 2-13, 2-14, 2-17, 2-20, 2-21, 2-22, 2-23, 2-24, 2-25, 3-1, 3-2, 3-3, 3-4, 3-5, 3-6, 3-7, 3-8, 3-9, 3-10, 3-11, 3-12, 3-13, 3-14, 3-21, 3-22, 3-23, 3-24, 3-25, 4-1, 4-2, 4-3, 4-4, 4-5, 4-6, 4-7, 4-8, 4-9, 4-10,4-11, 4-12, 4-13, 4-14, 4-21, 4-23, 4-24, 4-25, 5-1, 5-2, 5-3, 5-4, 5-5, 5-6, 5-7, 5-8, 5-9, 5-10, 5-11, 5-12, 5-13, 5-21, 5-23, 5-24, 5-25, 6-1, 6-2, 6-3, 6-4, 6-5, 6-6, 6-7, 6-8, 6-9. 6-10, 6-11, 6-12, 6-21, 6-22, 6-23, 6-24, 6-25, 7-1, 7-2, 7-3, 7-4, 7-5, 7-6, 7-7, 7-8, 7-9, 7-10, 7-11, 7-12, 7-21, 7-22, 7-23, 7-24, 8-1,8-2, 8-3, 8-4, 8-5, 8-6, 8-7, 8-8, 8-9, 8-10, 8-11, 8-19, 8-20, 8-23, 9-1, 9-2, 9-3, 9-4, 9-5, 9-6, 9-7, 9-8, 9-9, 9-10, 10-1, 10-2, 10-3, 10-4, 10-5, 10-6, 10-7, 10-8, 10-9, 10-10, 10-25, 11-1, 11-2, 11-3, 11-4, 11-5, 11-6, 11-7, 11-8, 11-9, 11-10, 11-21, 11-25, 12-1, 12-2, 12-3, 12-4, 12-5, 12-6, 12-7, 12-8, 12-9, 12-20, 12-21, 12-25, 13-1, 13-2, 13-3, 13-4, 13-5, 13-6, 13-8, 13-9, 13-24, 13-25, 14-1, 14-2, 14-3, 14-4, 14-5, 14-6, 14-7, 14-24, 15-1, 15-2, 15-3, 15-4, 15-5, 15-6, 15-7, 15-21, 15-24, 16-1, 16-2, 16-3, 16-4, 16-5, 16-6, 16-19, 16-20, 16-21, 16-22, 16-23, 16-24, 16-25, 17-1, 17-2, 17-3, 17-4, 17-5, 17-19, 17-20, 17-21, 17-22, 17-23, 17-24, 17-25, 18-1, 18-2, 18-3, 18-13, 18-14, 18-15, 18-16, 18-17, 18-18, 18-19, 18-20, 18-21, 18-22, 18-23, 18-24, 18-25, 19-1, 19-2, 19-12, 19-13, 19-14, 19-15, 19-16, 19-17, 19-18, 19-19, 19-20, 19-21, 19-22, 19-23, 19-24, 19-25, 20-1, 20-11, 20-12, 20-13, 20-14, 20-15, 20-16, 20-17, 20-18, 20-19, 20-20, 20-21, 20-22, 20-23, 20-24, 20-25, 21-11, 21-12, 21-13, 21-14, 21-15, 21-16, 21-17, 21-18, 21-19, 21-20, 21-21, 21-22, 21-23, 21-24, 21-25, 22-9, 22-10, 22-11, 22-12, 22-13, 22-14, 22-15, 22-16, 22-17, 22-18, 22-19, 22-20, 22-21, 22-22, 22-23, 22-24, 22-25, 23-10, 23-11, 23-12, 23-13, 23-14, 23-15, 23-16, 23-17, 23-18, 23-19, 23-20, 23-21, 23-22, 23-23, 23-24, 23-25, 24-7, 24-8, 24-10, 24-11, 24-12, 24-13, 24-14, 24-15, 24-16, 24-17, 24-18, 24-19, 24-20, 24-21, 24-22, 24-23, 24-24, 24-25, 25-1, 25-2, 25-5, 25-6, 25-7, 25-8, 25-10, 25-11, 25-12, 13, 25-14, 25-15, 25-16, 25-17, 25-18, 25-19, 25-20, 25-21, 25-22, 25-23, 25-24, 25-25  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: no se puede borrar '../proyecto_dev/data/dataset/train/satellite/20/zoom_20_16-8.jpg': No existe el archivo o el directorio\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_economic\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "7\n",
      "13\n",
      "45\n",
      "96\n",
      "214\n",
      "satellite\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "7\n",
      "13\n",
      "45\n",
      "96\n",
      "214\n",
      "TRAIN\n",
      "layer_economic\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "7\n",
      "16\n",
      "51\n",
      "114\n",
      "245\n",
      "satellite\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "7\n",
      "16\n",
      "51\n",
      "114\n",
      "246\n"
     ]
    }
   ],
   "source": [
    "lista = !ls ../proyecto_dev/data/dataset/test\n",
    "for i in lista:\n",
    "    L = !ls ../proyecto_dev/data/dataset/test/{i}\n",
    "    print(i)\n",
    "    for j in L:\n",
    "        M = !ls ../proyecto_dev/data/dataset/test/{i}/{j}\n",
    "        for k in M:\n",
    "            O = !ls ../proyecto_dev/data/dataset/test/{i}/{j}\n",
    "        print(len(O))\n",
    "        #for k in !ls\n",
    "\n",
    "print(\"TRAIN\")\n",
    "        \n",
    "lista = !ls ../proyecto_dev/data/dataset/train\n",
    "for i in lista:\n",
    "    L = !ls ../proyecto_dev/data/dataset/train/{i}\n",
    "    print(i)\n",
    "    for j in L:\n",
    "        M = !ls ../proyecto_dev/data/dataset/train/{i}/{j}\n",
    "        for k in M:\n",
    "            O = !ls ../proyecto_dev/data/dataset/train/{i}/{j} \n",
    "        print(len(O))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
