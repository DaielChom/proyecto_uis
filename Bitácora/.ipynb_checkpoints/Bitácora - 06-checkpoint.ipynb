{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitacora - 06\n",
    "\n",
    "#### 16 - Feb - 18:\n",
    "\"Señoras y caballeros mi saludos mis repseto co el permiso de uds voy a cantar unos verbos.\" Las cosas Se tornaron algo extraño pero a la vez no creo que cambie nada. La reunion de raul nos dejo impactados, una gran noticia la verdad, raul va a renunciar, ya no hay muhco que hacer, teniamos dos opciones o seguir trabajando con el por skype o buscar a otro profesor para hacer proyecto de grado con él, sin dudarlo todos queremos seguir con raul y la verdad si quisiera trabajar con el, espero no surga nada raro y el man no nos deje botados, pero pues confiar en el por ahora a ver que tal, seguire el consejo de @Jez y hare una prueba por un tiempoa ver como me va, pero bueno en otras noticias, lo que me antañe y es que de las dudas a hablar con él de la bitacora anterior, me dijo que dejara el trabajo de secretaria, que perder el tiempo buscando un archivo lo pelaba, que usara los kml a los uqe tenia acceso y ahi se hace algo, es decir si encuentro un kml de las victimas o de seguridad usarlo, que si lo encuentro a nivel nacional pues no pasa nada usarlo a nivel nacional o departamental que no hay afan. y yo quede como :O ese homrbe siempre piensa en las ideas que uno no piensa jajajajajaja es un bueno cucho pa que. Entoncs eso hare, entre todas las paginas donde puedo obtener kml, osea si los puedo descargar vere cual escoger, eso si tengo que enviar un correo a fabio y raul para ver que hacer en la aux, que tambien me tienen sin trabajo en eso, osea estoy como que hheeee y ahora que?. Entoncs la cuestion queda asi.\n",
    "##### Tarea:\n",
    "* Seleccionar las paginas donde puedo descargar los kml facilmente.\n",
    "* Escoger el KML que mas me llame la atencion en trabajar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 19 - Feb - 18:\n",
    "\"Y me sigo molestando por ella, no se ya que sera, aunque creo que si es normal en mi, recuerdi lo de laura tambien fue bastante tiempo, aunq tmabien amistades com la de jez y erika y sacaron la rabia, la de pili me dolio reguero y aun hoy en dia de vez en cuando me achicopalo por eso\" No se si ya haya escrito pero la reunion salio mas X. no recordaba la vbitacora 6. La cuestion es que no hice nada el fin de semana y hoy empezare la seleccion de KML, sigo pensando si meterle mano al json, por ahora vere mejor los kmls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mandar correo con las fechas,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20 - Feb - 18:\n",
    "Cambio nuevamente. O bueno, organizo ideas, por que estaba echo bolas, ya estaba dispuesto a cambiar de proyecto cuando no habia dado todo por luchar, me deje un poco influenciar y desde jeffer hasta jez, pasando con todos los uqe hable, tienen razon aun puedo ponerme hacer los mapas, seria algo complicado y canson pero lo puedo hacer, es trabajo de secretaria si, pero es por algo que realmente quiero hacer, incluso puedo buscar el mapa de estratos en pdf de otras ciudades hacer el mapa y con eso testiar, incluso jez me hizo pensar mientras estoy entranando o probando algo, puedo ir haciendo los otros mapas, incluso podria ser algo como de dia programacion y de noche adelanto mapas, sera engorrozo, pero dedicarme a hacer otra cosa desde casi 0 no quiero, no puedo quedarme sin haber luchado o estar inconforme por que no me dieron algo asi facilito, donde esta el daniel insistente y fastidioso, haceindo mapas hp, del afan y las ocsas borre el README pero no importa se puede volver a restaurar o algo asi, no hay afan, se pueden sacar los archivos de temp, o puede que no, y si hare eso, aprender react tendra que esperar un rato y me dedicare a hacer mapas en las noches, mañana tengo la sustentacion de wilson asi que tampoco es que vaya a aprovehar mucho el dia de mañana, y aun tengo que hablar con fabio y seguir pedaliando, reitero, gracias jeffer, gracias jez, gracias aron y angelica, el ceo y rueda, tellez y ahi a medio velandia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 22 - Feb - 18:\n",
    "Hoy me reuni de nuevo con raul y hable del proyecyo le dije que iba a ahcer el mapa y pues dijo que si que rela que lo hiciera y que despues lo publicara y que bueno que le hiciera quiero aprovechara poner esto \n",
    "![licencia](./img/mapas_bogota_licencia.png)\n",
    "![licencia](./img/mapas_bogota_licencia_02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedo modificar, obivamente debo publicarlo pero lo que estoy haceindo no es ilegal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Reunion 2 - Mar - 18:\n",
    "Raulito estaba como rarito hoy, no se que pero lo note un tris que no era él mismo. Y respecto al tabjajo de grado voy bien, bastante bien, me adelante un poco, a lo que tenia pensado qeu estaba haciendo. Primero, antes de la reunion que acabo de tener con él tenia unas cuantas dudas.\n",
    "\n",
    "##### Dudas\n",
    "* moestratle el dataset sin etiquetar\n",
    "* ,mostrat pero dataset\n",
    "* como seria la etiquetacion\n",
    "* explicarle si seguir ocn ihistogramas o q\n",
    "* como seria la etiquetacion\n",
    "* mas mapas\n",
    "* como afectarian los colores?\n",
    "* mas ciudades?\n",
    "* mas zooms?\n",
    "\n",
    "Y varias de estas dudas eran por que estaba pensando en trabajar con clasificacion, pero por x motivo alparcer y ahora, y mejor para mi, voy a trabjar es con segmentacion, lo que me da a pensar sobre la calidad del mapa que tengo, pero es complicado por que para volverlo a hacer y esta vez de buena manera como que no, podria trabajar asi, ajj la madre, podria trabajar en las noches en la elaboracion de ese mapa y sus 40k casitas por que esa parte de segmentacion si requiere un mejor trabajo en el mapa, creo que trataré de ahcer eso en las noches voy a ver, mientras tambien debo descargar mas imagenes de zoom, y a la vez probar alguna red neuronal o algo sobre segmentacion, eso si me toca consultar a ver que encuentro, la cuestion es como que hacer un tutorial de segmentacion y luego hacer una codigo que comapre ambas imagenes la real con la que se predijo en la seccmentacion, tambien debo adelantar cositas de los mapas extras. y pues segun las fechas voy bien pues ya tengo el dataset, solo es hacer un tutorial de segmentacion con lo que tengo, aunque ueno aun me falta arreglar unas cosas del dataset, como borrar las imagenes que estan grises y eso entoncs las tareas quedan asi.\n",
    "\n",
    "###### Tarea.\n",
    "* Terminar de Arreglar Dataset.\n",
    "* **Hacer mapa de estratos de calidad** --> **DUDA PARA DESPUES** --> dado que ese kml lo hice pensando en clasificacion mas que en segementacion\n",
    "* Hacer tutorial de Segmentacion - Buscando si se pueden ingresar varios canales (mapas) y ver si requiere un tamaño de imagen especifico.\n",
    "* **Descargar mas zooms**\n",
    "* **Hacer mapas extra**\n",
    "* hacer algoritmo para comparar la imagen real y la prediccion\n",
    "* Decidir train y test, de una manera un tanto geografico, es decir que no sea muy aleatorio dado que si dosimagenes muy cercanas entre si quedan una en train y la otra en test, se podria estar sesgando, entoncs toca como que encontrar una manera de dividir las imagenes en test y train, aunque eso podria haberlo echo con las imagnes mas grandes que tenia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Lunes 09 - Abr - 18:\n",
    "A partir de hoy creo que ya me podre dedicar a mi proyecto, adelante arto de la auxiliatura y tambien bastante del Diplomado, solo queda que Duvan me responda el correo, si esta noche no me ha respondido le envio otro correo, la cuestion es que podre dedciarme al proyecto y sera completamente hoy en sacar el dataser, nuevamente. Debo eliminar unos archivos para no procesar tantos, asi que eliminare las siguientes imagenes.\n",
    "\n",
    "#### Miercoles 11 - Abr - 18:\n",
    "Le mande un correo a raul quede, super estancado, ajjj aprendo Tensorflow asi de 0, o copio y pego los repositorios o que, la verdad estoy re confundido con que hacer, por que si aprendo tensorflow croe qeu quedaria mas facil despues implementar varias redes y probar a ver cual es mejor, o tna solo copiar y pegar asi a lo mula, se que no debi haber preguntado eso pero pues pa eso esta el cucho pa desahogarme un poco, por ahora terminare de crear el dataset, lo dejare todo de 512x256.\n",
    "\n",
    "##### Dudas:\n",
    "* ¿por que algunos modelos tienen algo preentrenado, osea eso no afecta la tarea?\n",
    "* Que sera mejor usar?, algun tutorial o aprender bien keras, usar caffe o tensorflow o pytorch o q :'( no entiendo.\n",
    "* a que se refiere a tensor como backend y keras como frontend.\n",
    "* Dividir al raz o sobrelapar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jueves 12 - Abr - 18:\n",
    "Ayer le mande un correo a raulsiño y no me respondio :( que triste :'(, por consejo de aron deberia aprnder tensorflow y probar varias redes, tambien me aconsejo probar con ambos dataset con el sobrelapado y con el que no y creo que no es mala idea hacerlo, alfin al cabo de eso trata la investigacion de ver que pasa no es mala idea, me dedicare a sacar ambos dataset a ver q, tambien tengo una reunion con Fabio ahorita a las 10 y pues no es mala idea preguntarle a él tambien a ver dice y con eso se por que camino tomar, lo otro es alguna otra idea para subdividir las imagenes, incluso podria envez de dividirlas agrandarlas y volverlas multiplo de 256 y 512 y ahi si dividirlas en partes iguales y sin \"repeticion\". hps necesito consejo de raul y fabio que son los duros en eso. :( ahora si bolsa ajajajaj\n",
    "Son las 3 de la tarde y hasta ahora entro a trabajar  ...xxxxx--.... esta mañan tuve la reunion con el profe fabio, y en parte la cage un poco y me dijo si un par de cosas buenas, en fin, primero llegue ha hablar respecto a lo de mooc-grader y en lo que la cague es que no llegue con las cosas ejecutadas, debi haber llegado con las cosas ejecutadas, pero pues no, pense que lo habia echo pero el repo como que lo acaba de limpiar y no llegue con nada, que pena enserio, todo dejo de funcionar justamente cuando le estaba explicando como funcionaba\n",
    ":'( va la popo, pero buneo a malas a primeras pues le mostre lo que habia echo y como funcionaba, las dudas que tenia las puse, ahi lo unico que si seria como a corregir era lo de \n",
    "\n",
    "* indicar que posiblemente poner o indicar que usar una cuenta de desarrollador de google\n",
    "* poner el enlace de la consola de google, de resto pues dijo que si que pro, peor todo fue como tan ajj ese man es u idiota :'( ajajjajajajaa pero bueno ya de eso salir por fin por asi decir a bueno falta\n",
    "* Hablar con raul para mostrarle lo que hice\n",
    "* hablar sobre lo del registro de la app\n",
    "\n",
    "Tengo pues esas tareillas sobre la auxiliatura, se que no deben ir aca pero despues se me olvida bien\n",
    "ya con lo que me importa que es el proyecto de grado, pues alfin y al cabo es mi nuevo director le explique que iba a hacer y como y con que y tales, al principio no nos estabamos haciendo entender estabamos comoq ue hablando de lo mismo pero con diferentes terminos entoncs estabamos como wtf! pero luego listo nos dimos a entender y dejando algunos alagas raros jajajaja me comento sobre\n",
    "\n",
    "* multimodal information - deep learning for multimodal information: que es como tecnicas para hacer fusion de distintos tipos de datos que hablan del mismo objeto, esto pues con la idea de lo de aplicar varios canales a la red neuronal.\n",
    "* Me aconsejo usar Tensoflow, por que 1 es una libreria respaldada por google la cual tiene una comunidad muy grande para dar soporte y ayudas, mientras que otras como caffe no tienen dicha calidad de ocmunidad por asi decirlo y pues ya dos duros en el mundo de machine learning me aconsejaron usarlo asi que pues eso es de peso para usarlo.\n",
    "* respecto a la division del dataset me aconsejo hacer el sobrelapado eso ayuda bastante al entrenamiento, hace que la prediccion sea mas demorada dado que habran mas datos, pero pues mi algoritmo no hace algo que ponga en riesgo la vida de las personas asi que no podria preocuparme la demora del entrenamiento y prediccion, y el sobrelapado me lo aconsejo a la mitad, que si al final sobra, pues si sobran alfin y alcabo son pocos pixeles en comparacion con toda la imagen asi que no habria probelma la verdad\n",
    "* respecto a que hacer me dijo, igual que bayona es coger un repo que ya este echo y jguar con el un rato envez de meterme con el funcionamiento de todo el framweork por que pa que, si ya esta echo lo que necesito mejor estudiar bien eso, como funciona, que por que las capas de esa red etc, incluso me dijo que si era posible usar un modelo ya entrenado seria genial. aunque eso me genea una **DUDA** la mayoria de modelos estan entrenados para encontrar perros o gatos o cosas asi, no se si eso me vaya a servir pa lo que tengo que hacer, aunque hay un par claro esta de imagenes satelitales, lo que si debo hacer es sacar y eliminar esas consultas que no usan tensorflow.\n",
    "* me dio una idea por asi decirlo que seria interesante montar un modelo donde se quiere encontrar un el estrato de un parche y se le entrege como input los parches vecinos a dicho parche, lo que habria que etiquetar de alguna manera los parches para saber cuales son vecinos de otros, por que eso por ahora no esta claro, y pues que eso para la parte donde habia un estrato 6 entre varios estrato 3, lo que tambien le daria razon al uso de otro tipos de datos, como los mapas estadisticos y eso.\n",
    "* hablar con raul a ver que opina de todo\n",
    "* mis datos estan mal balanceados, en especial hacia el estrato 3, fabio si me dijo que ahi hay debo tambien hacer algo. podria en algun punto del dataset mirar cuantos hay de cada etiqueta, que porsentadjes hay de cada estrato\n",
    "* **DUDA** ¿las imagenes a predecir las dejo de un solo canal?, siendo asi, ¿las redondeo?\n",
    " pues al hacer el mean saldran varios float y aparte depronto con una o dos unidades mas o menos. no tengo muy claro si seran 3 canales o solo 1 el de output.\n",
    "* si las funciones ya estan entrenadas pa buscar perros o gatos me servira?\n",
    " \n",
    "jajajja al final me dijo \"deja de hacer proyecticos y has tu proyecto\" y pues tiene razon y viendolo con la runion de hoy y temrino auxiliatura y ya la otra semana diplomado creo qeu por fin podre ponerme concentrado con el proyecto. pondre mis tareas en todoist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bueno hay varias dudas ai rondando asi que agrupandolas seria lo siguiente:\n",
    "#### DUDAS:\n",
    "* Usar TF o alguna otra\n",
    "* dividir solpando las imagenes o no\n",
    "* a que se refier a TF como backend y keras como frontend -> buscarla en internet\n",
    "* En que consiste o como ayuda el pre entrenameinto de algunos modelos\n",
    "* El profe fabio me hablo sobre multimodal information\n",
    "* que hacer, si coger un repo ya listo y explorarlo o meterme de a poco en TF\n",
    "* El profe fabio me aconsejo usar modelos ya entrenados, pero esos modelos en su mayoria estan entrenados para encontrar perros o gatos, eso no afectaria mis resultados?\n",
    "* El profe fabio me dijo que podria probar lo de la busqueda de vecinos\n",
    "* El profe fabio me indico que los datos estan mal balanceados\n",
    "* Las imagenes output deberian ser de un solo canal o de barios canales? si no, para arreglarlas.\n",
    "\n",
    "Solo queda esperar a que me responda para cuadrar una reunion con el."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mar 17 - Abr - 18:\n",
    "Bueno, pues muy chistozo, lo que me recuerda que hoy me vi todo el dia con Eri, luego un rato con jez, pero con ella si estuve algo de malas pulgas y luego me vi con san, cosita linda :3 y aproveche para molestar con eri ajjajaa otro amor divino para mi. EL viernes pasado tuve una reunion con raul por skype y no escribi en la bitacora y se me paso por alto y ahora no recuedo bien que mas hablamos pero sin embargo hare lo posible por escrbir que mas hable con él. Respecto al proyecto de grado, de lo de la aux lo hare ahorita, ya lo hice. Hubieron unas dudas que no pregunte las cuales prefiero buscarlas por mi misma  cuenta para tambien aprender, son dudas que creo podre encontrar en internet. \n",
    "\n",
    "1. Usar TF o alguna otra **RTA:** Tanto él como el profe fabio me recomeindan usar TF, asi que por esa razon y por lo de la comunidad usaré TF.\n",
    "2. dividir solpando las imagenes o no **RTA:** Es mejor hacer solapamiento, pero en vez de un 50% como me habia insinuado el profe fabio con un 20 o 30% bastaria, entoncs aqui nace la primera de las tareas a hacer **CREAR UN ALGORITMO PARA SUBDIVIDIR IMAGENES QUE ACEPTE UN PARAMETRO PARA EL % DE SOLAPAMIENTO, AUNQUE EL ALGORITMO YTA DEBE ESTAR POR AHI PDORIA BUSCARLO**\n",
    "3. a que se refier a TF como backend y keras como frontend **RTA:** buscarla en internet, pobrablemente lo encuentre en el transucurso del proyecto\n",
    "4. En que consiste o como ayuda el pre entrenameinto de algunos modelos. **RTA:** no recuerdo bien, raul me menciono algo al respecto, que ayuda para que luego el entrenamiento no sea tan pesado o algo por el estilo\n",
    "5. El profe fabio me hablo sobre multimodal information **RTA:** Es un tema para tratarlo despues, igual que el de los datos desvalanceados.\n",
    "6. que hacer, si coger un repo ya listo y explorarlo o meterme de a poco en TF **RTA:** Coger un repo ya echo y hacerlo funcionar, que probara con algo de TF + segnet que era algo rela, y que luego si me preocupara por mas cosas como entender la caja negra, por ahora hacer funcionar un repo y si es posible con mi propio dataset mejor. \n",
    "7. El profe fabio me aconsejo usar modelos ya entrenados, pero esos modelos en su mayoria estan entrenados para encontrar perros o gatos, eso no afectaria mis resultados? **RTA:** Tambien lo mencione pero no recuerd que dijo, sin embargo me dijo que probará con lo del repo\n",
    "8. El profe fabio me dijo que podria probar lo de la busqueda de vecinos **NOTA:** me falto mencionarlo\n",
    "9. El profe fabio me indico que los datos estan mal balanceados **RTA:** Algo que debo ver despues, sin embargo si me pidio que tratara de **CUANTIFICAR EL % DE CADA CLASE EN EL DATASET** he aqui la segunda tarea.\n",
    "10. Las imagenes output deberian ser de un solo canal o de barios canales? si no, para arreglarlas. **RTA:**\n",
    " ~~Buscarlo en internet~~ viendo el repo de raul lasiamgenes layer tambien son RGB osea 3 canales pero cada clase esta bien definida es decir azul es [0, 0, 255] y no hay otros tipos de azul, buneo claro a menos de que la cantidad de clases lo requieran, el caso es qeu colores bien definidos, tambien debo revisar eso en mi dataset otra tarea **REVISAR EXACTITUD DE LOS CODIGOS RGB DE LAS CLASES**\n",
    " \n",
    "Una de las tantas cosas que menciono raul fue que no importaba que al principio lo viera todo como una caa negra, ue hiciera funcionar un repo y que en el proceso iria tanto aprendiendo TF como aprendiendo sobre redes y eso, que luego si despues de que funcionará iba revisando si que hacia cada cosa, y pues en retrospectiva eso fue lo que me paso con Docker con lo de kobotoolbox, lo hice funcionar y luego si entendi como era la cosa, de resto pues fue que si que muy bien, las palabras esas de apoyo que ya a ratos me saben a que lo dicen pues por su papel de guias, bien pero pues con lo gonorrea que soy ahsta me da rabia, por que no me regañan (T-T). quiero que me regañen debes en cuando. de resto pus ahi estan las treas, hoy fue genail, hable con Eri, Jez, Lina y La mas querida de todas mi San linda. aunque con jez estaba como de malas pulgas con ella estaba algo celoso otra vez XD que no se entere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
