{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training OVERLAECOBO\n",
    "En este notebook se llevaran acabo las pruebas con OVERLAECOBO, se probaran los distintos ZOOMS y la informacion extra para asi escoger la mejor configuracion de dataset y de red neuronal. Como primer paso sera obtener el repositorio donde estan las redes entrenadas y preparalo para su funcionamiento con OVERLAECOBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/GeorgeSeif/Semantic-Segmentation-Suite.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Que pruebas se van a realizar?\n",
    "* Un entrenamiento con cada uno de los zooms sin informacion aumentada\n",
    "* Un entrenamiento con cada uno de los zooms con informacion aumentada\n",
    "\n",
    "Las pruebas tendran la etiqueta del lugar donde fueron realizadas, esto debido a que hoy (24 - 05 -18) aun no tengo una cuenta e guane, sin olvidar que cuando la tenga debo hacer configuraciones e instalar tensorflow lo que conllevara bastante tiempo, tiempo en el que podria hacer pruebas en mi pc. Tambien se documentará los parametros a usar, epoch, batch_size, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparar el dataset para usar la Suite\n",
    "Dado que la suite tiene su propia estructura para el dataset, se hace necesario cambiar los directorios a dicha estructura, y aqui se presenta un inconveniente y es que segun un [issue](https://github.com/GeorgeSeif/Semantic-Segmentation-Suite/issues/65) que encontre hoy (24 - 05 - 18 7:18 am) y segun eso de hace una hora, en el framework no usan las imagenes de test, entonces:\n",
    "1.  mi test se vuelve el nuevo valid y no existitian imagenes para test y siguo usando el framework\n",
    "2. cambio todo lo interno del repo para que use test y duro otra semana sacando mi dataset con la nueva division de 3 partes y no solo dos como lo hice\n",
    "3. busco otro repositorio\n",
    "\n",
    "Me quedaré con la segunda opcion, la tercera no me cuadra ya con este esta sirviendo, podria atacar el problema con otras cuestiones, primero el issue es muy reciente y podria estar pendiente de cuando haga los arreglos y pues solo seria volver a copiar el repo y si no dan solucion tan solo crear un metodo para sacar un score, para predecir se predice con una imagen, le paso for a la carpeta test, que predicga y luego trato de sacar algun score haciedno comparaciones alfin y alcabo la cuestion es de que entrene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Restructurando dataset\n",
    "La suite pide una estrucutra de dataset de la siguiente manera.\n",
    "\n",
    "           - dataset\n",
    "               - train\n",
    "               - train_labels\n",
    "               - valid\n",
    "               - valid_labels\n",
    "               - class_dict.scv\n",
    "\n",
    "cabe aclarar que esta vendria siendo la estructura para un unico zoom asi que dentro de la carpeta actual de OVERLAECOBO creare nuevas carpetas con cada zoom y luego dentro dividir en train y valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    os.mkdir(\"./data/dataset/OVERLAECOBO/OVERLAECOBO_\"+str(i+13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    os.rename(\"./data/dataset/OVERLAECOBO/train/satellite/\"+str(i+13), \"./data/dataset/OVERLAECOBO/OVERLAECOBO_\"+str(i+13)+\"/train\")\n",
    "    os.rename(\"./data/dataset/OVERLAECOBO/train/economic_layer/\"+str(i+13), \"./data/dataset/OVERLAECOBO/OVERLAECOBO_\"+str(i+13)+\"/train_labels\")\n",
    "    os.rename(\"./data/dataset/OVERLAECOBO/test/satellite/\"+str(i+13), \"./data/dataset/OVERLAECOBO/OVERLAECOBO_\"+str(i+13)+\"/val\") \n",
    "    os.rename(\"./data/dataset/OVERLAECOBO/test/economic_layer/\"+str(i+13), \"./data/dataset/OVERLAECOBO/OVERLAECOBO_\"+str(i+13)+\"/val_labels\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queria copiar con codigo los archivos class_dict pero al parece la libreia os no tiene un `cp` y con shutil habia como 4 metodos para copiar, aisque lo hice manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Switch Train Test\n",
    "Dado que al parecer las carpetas valid tienes mas datos de las de train hare un switch entoncs valid pasara a ser train y train valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    os.rename(\"./OVERLAECOBO_\"+str(i+14)+\"/train\",\"./OVERLAECOBO_\"+str(i+14)+\"/pibote\")\n",
    "    os.rename(\"./OVERLAECOBO_\"+str(i+14)+\"/train_labels\",\"./OVERLAECOBO_\"+str(i+14)+\"/pibote_labels\")\n",
    "    os.rename(\"./OVERLAECOBO_\"+str(i+14)+\"/valid\",\"./OVERLAECOBO_\"+str(i+14)+\"/train\")\n",
    "    os.rename(\"./OVERLAECOBO_\"+str(i+14)+\"/valid_labels\",\"./OVERLAECOBO_\"+str(i+14)+\"/train_labels\")\n",
    "    os.rename(\"./OVERLAECOBO_\"+str(i+14)+\"/pibote\",\"./OVERLAECOBO_\"+str(i+14)+\"/val\")\n",
    "    os.rename(\"./OVERLAECOBO_\"+str(i+14)+\"/pibote_labels\",\"./OVERLAECOBO_\"+str(i+14)+\"/val_labels\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Metricas\n",
    "Al parecer el framework usa varias metricas provenientes de sklearn, y lo se dado a que en uno de sus archivos `.py` se encuentra el siguiente import\n",
    "\n",
    "      from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "   \n",
    "y mirando en la documentacion de sklearn, dichas metricas significan [precision_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score), [recall_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score), [f1_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score)\n",
    "\n",
    "## 3. Pruebas\n",
    "Y por ahora (24 - May - 2018) que aun no tengo la cuenta de guane iniciare las pruebas e mi GPU y con los ZOOMs mas grandes puesto que hay menos imagenes. una de las cosas es que podria probar varios modelos, entre los que permite la suite\n",
    "\n",
    "* DenseNet56\n",
    "* FC-DenseNet67\n",
    "* FC-DenseNet103 \n",
    "* Encoder-Decoder\n",
    "* Encoder-Decoder-Skip\n",
    "* RefineNet-Res50\n",
    "* RefineNet-Res101 \n",
    "* RefineNet-Res152\n",
    "* FRRN-A\n",
    "* FRRN-B\n",
    "* MobileUNet\n",
    "* MobileUNet-Skip\n",
    "* PSPNet-Res50 \n",
    "* PSPNet-Res101\n",
    "* PSPNet-Res152\n",
    "* GCN-Res50 \n",
    "* GCN-Res101\n",
    "* GCN-Res152\n",
    "\n",
    "Para cada prueba se realizara un train, un test y un predcit. el predict será de una imagen cualquiera del directorio valid\n",
    "\n",
    "### 3.1 Sin Información extra\n",
    "\n",
    "Las pruebas a realizar a continuacion son pruebas echas meramente con los 3 canales de una imagen RGB, para las pruebas con informacion extra se agregaran uno o mas canales, dependiendo de la informacion obtenida y la capacidad del framework\n",
    "\n",
    "<h4 style=\"color:#c62828\"> Prueba # 1 </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba multi capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    img = io.imread(\"./OVERLAECOBO_13_multi/train/\"+str(i)+\".png\")\n",
    "    d = img.flatten()\n",
    "    f = list(d) + list(d)\n",
    "    g = np.array(f).reshape((256,256,6))[:,:,:4]\n",
    "    io.imsave(\"./OVERLAECOBO_13_multi/train/\"+str(i)+\".png\",g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = io.imread(\"./OVERLAECOBO_13_multi/train/0.tiff\")\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRUEBAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    FC-DenseNet56\n",
    "    FC-DenseNet67\n",
    "    FC-DenseNet103\n",
    "    Encoder-Decoder\n",
    "    Encoder-Decoder-Skip\n",
    "    RefineNet-Res50\n",
    "    RefineNet-Res101\n",
    "    RefineNet-Res152\n",
    "    FRRN-A\n",
    "    FRRN-B\n",
    "    MobileUNet\n",
    "    MobileUNet-Skip\n",
    "    PSPNet-Res50\n",
    "    PSPNet-Res101\n",
    "    PSPNet-Res152\n",
    "    GCN-Res50\n",
    "    GCN-Res101\n",
    "    GCN-Res152\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================ ZOOM 13 =============================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "====== FC-DenseNet56 ============"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN \n",
      "python main.py --mode train --dataset OVERLAECOBO_13 --crop_height 256 --crop_width 256 --num_epochs 50 --batch_size 1 --model FC-DenseNet56\n",
      "\n",
      "TEST \n",
      "python main.py --mode test --dataset OVERLAECOBO_13 --crop_height 256 --crop_width 256 --num_epochs 50 --batch_size 1 --model FC-DenseNet56\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = \"OVERLAECOBO_13\"\n",
    "CROP_SIZE = 256\n",
    "NUM_EPOCH = 70\n",
    "BATCH_SIZE = 1 # Hay pocas imagenes por ende se prueba con un batch pequeño y al usar 2 sale un error que no se que sera pero creo que es algo con la GPU\n",
    "MODEL = \"FC-DenseNet56\"\n",
    "print(\"TRAIN \\npython main.py --mode train --dataset\",DATASET_PATH, \"--crop_height\",CROP_SIZE,\"--crop_width\",CROP_SIZE,\"--num_epochs\",NUM_EPOCH,\"--batch_size\",BATCH_SIZE,\"--model\",MODEL)\n",
    "print(\"\")\n",
    "print(\"TEST \\npython main.py --mode test --dataset\",DATASET_PATH, \"--crop_height\",CROP_SIZE,\"--crop_width\",CROP_SIZE,\"--num_epochs\",NUM_EPOCH,\"--batch_size\",BATCH_SIZE,\"--model\",MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN \n",
      "python main.py --mode train --dataset OVERLAECOBO_13 --crop_height 256 --crop_width 256 --num_epochs 50 --batch_size 5 --model FC-DenseNet56\n",
      "\n",
      "TEST \n",
      "python main.py --mode test --dataset OVERLAECOBO_13 --crop_height 256 --crop_width 256 --num_epochs 50 --batch_size 5 --model FC-DenseNet56\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = \"OVERLAECOBO_13\"\n",
    "CROP_SIZE = 256\n",
    "NUM_EPOCH = 70\n",
    "BATCH_SIZE = 2 # Hay pocas imagenes por ende se prueba con un batch pequeño y al usar 2 sale un error que no se que sera pero creo que es algo con la GPU\n",
    "MODEL = \"FC-DenseNet56\"\n",
    "print(\"TRAIN \\npython main.py --mode train --dataset\",DATASET_PATH, \"--crop_height\",CROP_SIZE,\"--crop_width\",CROP_SIZE,\"--num_epochs\",NUM_EPOCH,\"--batch_size\",BATCH_SIZE,\"--model\",MODEL)\n",
    "print(\"\")\n",
    "print(\"TEST \\npython main.py --mode test --dataset\",DATASET_PATH, \"--crop_height\",CROP_SIZE,\"--crop_width\",CROP_SIZE,\"--num_epochs\",NUM_EPOCH,\"--batch_size\",BATCH_SIZE,\"--model\",MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "====== FC-DenseNet67 ============"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"OVERLAECOBO_13\"\n",
    "CROP_SIZE = 256\n",
    "NUM_EPOCH = 50\n",
    "BATCH_SIZE = 1 # Hay pocas imagenes por ende se prueba con un batch pequeño y al usar 2 sale un error que no se que sera pero creo que es algo con la GPU\n",
    "MODEL = \"FC-DenseNet67\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"OVERLAECOBO_13\"\n",
    "CROP_SIZE = 256\n",
    "NUM_EPOCH = 50\n",
    "BATCH_SIZE = 1 # Hay pocas imagenes por ende se prueba con un batch pequeño y al usar 2 sale un error que no se que sera pero creo que es algo con la GPU\n",
    "MODEL = \"FC-DenseNet103\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"OVERLAECOBO_13\"\n",
    "CROP_SIZE = 256\n",
    "NUM_EPOCH = 50\n",
    "BATCH_SIZE = 1 # Hay pocas imagenes por ende se prueba con un batch pequeño y al usar 2 sale un error que no se que sera pero creo que es algo con la GPU\n",
    "MODEL = \"Encoder-Decoder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"OVERLAECOBO_13\"\n",
    "CROP_SIZE = 256\n",
    "NUM_EPOCH = 50\n",
    "BATCH_SIZE = 1 # Hay pocas imagenes por ende se prueba con un batch pequeño y al usar 2 sale un error que no se que sera pero creo que es algo con la GPU\n",
    "MODEL = \"RefineNet-Res50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
