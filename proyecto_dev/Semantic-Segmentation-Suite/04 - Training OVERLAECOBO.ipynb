{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training OVERLAECOBO\n",
    "En este notebook se llevaran acabo las pruebas con OVERLAECOBO, se probaran los distintos ZOOMS y la informacion extra para asi escoger la mejor configuracion de dataset y de red neuronal. Como primer paso sera obtener el repositorio donde estan las redes entrenadas y preparalo para su funcionamiento con OVERLAECOBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/GeorgeSeif/Semantic-Segmentation-Suite.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Que pruebas se van a realizar?\n",
    "* Un entrenamiento con cada uno de los zooms sin informacion aumentada\n",
    "* Un entrenamiento con cada uno de los zooms con informacion aumentada\n",
    "\n",
    "Las pruebas tendran la etiqueta del lugar donde fueron realizadas, esto debido a que hoy (24 - 05 -18) aun no tengo una cuenta e guane, sin olvidar que cuando la tenga debo hacer configuraciones e instalar tensorflow lo que conllevara bastante tiempo, tiempo en el que podria hacer pruebas en mi pc. Tambien se documentará los parametros a usar, epoch, batch_size, etc.\n",
    "\n",
    "## 1. Preparar el dataset para usar la Suite\n",
    "Dado que la suite tiene su propia estructura para el dataset, se hace necesario cambiar los directorios a dicha estructura, y aqui se presenta un inconveniente y es que segun un [issue](https://github.com/GeorgeSeif/Semantic-Segmentation-Suite/issues/65) que encontre hoy (24 - 05 - 18 7:18 am) y segun eso de hace una hora, en el framework no usan las imagenes de test, entonces:\n",
    "1.  mi test se vuelve el nuevo valid y no existitian imagenes para test y siguo usando el framework\n",
    "2. cambio todo lo interno del repo para que use test y duro otra semana sacando mi dataset con la nueva division de 3 partes y no solo dos como lo hice\n",
    "3. busco otro repositorio\n",
    "\n",
    "Me quedaré con la segunda opcion, la tercera no me cuadra ya con este esta sirviendo, podria atacar el problema con otras cuestiones, primero el issue es muy reciente y podria estar pendiente de cuando haga los arreglos y pues solo seria volver a copiar el repo y si no dan solucion tan solo crear un metodo para sacar un score, para predecir se predice con una imagen, le paso for a la carpeta test, que predicga y luego trato de sacar algun score haciedno comparaciones alfin y alcabo la cuestion es de que entrene\n",
    "\n",
    "### 1.1 Restructurando dataset\n",
    "La suite pide una estrucutra de dataset de la siguiente manera.\n",
    "\n",
    "           - dataset\n",
    "               - train\n",
    "               - train_labels\n",
    "               - valid\n",
    "               - valid_labels\n",
    "               - class_dict.scv\n",
    "\n",
    "cabe aclarar que esta vendria siendo la estructura para un unico zoom asi que dentro de la carpeta actual de OVERLAECOBO creare nuevas carpetas con cada zoom y luego dentro dividir en train y valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    os.mkdir(\"./data/dataset/OVERLAECOBO/OVERLAECOBO_\"+str(i+13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    os.rename(\"./data/dataset/OVERLAECOBO/train/satellite/\"+str(i+13), \"./data/dataset/OVERLAECOBO/OVERLAECOBO_\"+str(i+13)+\"/train\")\n",
    "    os.rename(\"./data/dataset/OVERLAECOBO/train/economic_layer/\"+str(i+13), \"./data/dataset/OVERLAECOBO/OVERLAECOBO_\"+str(i+13)+\"/train_labels\")\n",
    "    os.rename(\"./data/dataset/OVERLAECOBO/test/satellite/\"+str(i+13), \"./data/dataset/OVERLAECOBO/OVERLAECOBO_\"+str(i+13)+\"/val\") \n",
    "    os.rename(\"./data/dataset/OVERLAECOBO/test/economic_layer/\"+str(i+13), \"./data/dataset/OVERLAECOBO/OVERLAECOBO_\"+str(i+13)+\"/val_labels\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queria copiar con codigo los archivos class_dict pero al parece la libreia os no tiene un `cp` y con shutil habia como 4 metodos para copiar, aisque lo hice manual\n",
    "### 1.2 Switch Train Test\n",
    "Dado que al parecer las carpetas valid tienes mas datos de las de train hare un switch entoncs valid pasara a ser train y train valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    os.rename(\"./OVERLAECOBO_\"+str(i+14)+\"/train\",\"./OVERLAECOBO_\"+str(i+14)+\"/pibote\")\n",
    "    os.rename(\"./OVERLAECOBO_\"+str(i+14)+\"/train_labels\",\"./OVERLAECOBO_\"+str(i+14)+\"/pibote_labels\")\n",
    "    os.rename(\"./OVERLAECOBO_\"+str(i+14)+\"/valid\",\"./OVERLAECOBO_\"+str(i+14)+\"/train\")\n",
    "    os.rename(\"./OVERLAECOBO_\"+str(i+14)+\"/valid_labels\",\"./OVERLAECOBO_\"+str(i+14)+\"/train_labels\")\n",
    "    os.rename(\"./OVERLAECOBO_\"+str(i+14)+\"/pibote\",\"./OVERLAECOBO_\"+str(i+14)+\"/val\")\n",
    "    os.rename(\"./OVERLAECOBO_\"+str(i+14)+\"/pibote_labels\",\"./OVERLAECOBO_\"+str(i+14)+\"/val_labels\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Metricas\n",
    "Al parecer el framework usa varias metricas provenientes de sklearn, y lo se dado a que en uno de sus archivos `.py` se encuentra el siguiente import\n",
    "\n",
    "      from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "   \n",
    "y mirando en la documentacion de sklearn, dichas metricas significan [precision_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score), [recall_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score), [f1_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score)\n",
    "\n",
    "## 3. Pruebas\n",
    "Y por ahora (24 - May - 2018) que aun no tengo la cuenta de guane iniciare las pruebas e mi GPU y con los ZOOMs mas grandes puesto que hay menos imagenes. una de las cosas es que podria probar varios modelos, entre los que permite la suite\n",
    "\n",
    "* DenseNet56\n",
    "* FC-DenseNet67\n",
    "* FC-DenseNet103 \n",
    "* Encoder-Decoder\n",
    "* Encoder-Decoder-Skip\n",
    "* RefineNet-Res50\n",
    "* RefineNet-Res101 \n",
    "* RefineNet-Res152\n",
    "* FRRN-A\n",
    "* FRRN-B\n",
    "* MobileUNet\n",
    "* MobileUNet-Skip\n",
    "* PSPNet-Res50 \n",
    "* PSPNet-Res101\n",
    "* PSPNet-Res152\n",
    "* GCN-Res50 \n",
    "* GCN-Res101\n",
    "* GCN-Res152\n",
    "\n",
    "Para cada prueba se realizara un train, un test y un predcit. el predict será de una imagen cualquiera del directorio valid\n",
    "\n",
    "### 3.1 Sin Información extra\n",
    "\n",
    "Las pruebas a realizar a continuacion son pruebas echas meramente con los 3 canales de una imagen RGB, para las pruebas con informacion extra se agregaran uno o mas canales, dependiendo de la informacion obtenida y la capacidad del framework\n",
    "\n",
    "## Prueba multi capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    img = io.imread(\"./OVERLAECOBO_13_multi/train/\"+str(i)+\".png\")\n",
    "    d = img.flatten()\n",
    "    f = list(d) + list(d)\n",
    "    g = np.array(f).reshape((256,256,6))[:,:,:4]\n",
    "    io.imsave(\"./OVERLAECOBO_13_multi/train/\"+str(i)+\".png\",g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = io.imread(\"./OVERLAECOBO_13_multi/train/0.tiff\")\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Pruebas\n",
    "Cada una de las pruebas tendra su propio notebook por cada nivel de Zoom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> RESULTADOS</h1></center>\n",
    "\n",
    "Acontinuacion los resultados de las distintas pruebas realizadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_PRUEBAS = \"./Pruebas/OVERLAECOBO_#\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OVERLAECOBO 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZOOM = \"13\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las pruebas realizadas con OVERLAECOBO_13 fueron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRUEBA</th>\n",
       "      <th>RED</th>\n",
       "      <th>EPOCH</th>\n",
       "      <th>BATCH_SIZE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>FC-DenseNet56</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>FC-DenseNet56</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Encoder-Decoder</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Encoder-Decoder</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Encoder-Decoder-Skip</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Encoder-Decoder-Skip</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>FRRN-A</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>MobileUNet</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>MobileUNet</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>MobileUNet-Skip</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>MobileUNet-Skip</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PRUEBA                   RED   EPOCH   BATCH_SIZE\n",
       "0        1         FC-DenseNet56      50            1\n",
       "1        2         FC-DenseNet56      70            1\n",
       "2        3       Encoder-Decoder      70            1\n",
       "3        4       Encoder-Decoder      70            2\n",
       "4        5  Encoder-Decoder-Skip      70            1\n",
       "5        6  Encoder-Decoder-Skip      70            2\n",
       "6        7                FRRN-A      70            1\n",
       "7        8            MobileUNet      70            1\n",
       "8        9            MobileUNet      70            2\n",
       "9       10       MobileUNet-Skip      70            1\n",
       "10      11       MobileUNet-Skip      70            2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruebas = pd.read_csv(PATH_PRUEBAS.replace(\"#\",\"13\")+\"/pruebas.csv\")\n",
    "pruebas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./Pruebas/OVERLAECOBO_13/prueba_1/train.txt'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = PATH_PRUEBAS.replace(\"#\",ZOOM)+\"/prueba_\"+str(pruebas[\"PRUEBA\"][0])+\"/train.txt\"\n",
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El archivo train generado: [Train File](./Pruebas/OVERLAECOBO_13/prueba_1/train.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./Pruebas/OVERLAECOBO_13/prueba_1/accuracy_vs_epochs.png'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = PATH_PRUEBAS.replace(\"#\",ZOOM)+\"/prueba_\"+str(pruebas[\"PRUEBA\"][0])+\"/accuracy_vs_epochs.png\"\n",
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./Pruebas/OVERLAECOBO_13/prueba_1/accuracy_vs_epochs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./Pruebas/OVERLAECOBO_13/prueba_1/loss_vs_epochs.png'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = PATH_PRUEBAS.replace(\"#\",ZOOM)+\"/prueba_\"+str(pruebas[\"PRUEBA\"][0])+\"/loss_vs_epochs.png\"\n",
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./Pruebas/OVERLAECOBO_13/prueba_1/loss_vs_epochs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TEST RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_name</th>\n",
       "      <th>avg_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1 score</th>\n",
       "      <th>mean iou</th>\n",
       "      <th>Estrato_1</th>\n",
       "      <th>Estrato_2</th>\n",
       "      <th>Estrato_3</th>\n",
       "      <th>Estrato_4</th>\n",
       "      <th>Estrato_5</th>\n",
       "      <th>Estrato_6</th>\n",
       "      <th>No_Definido</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.109436</td>\n",
       "      <td>0.403108</td>\n",
       "      <td>0.109436</td>\n",
       "      <td>0.078118</td>\n",
       "      <td>0.039587</td>\n",
       "      <td>0.082335</td>\n",
       "      <td>0.251546</td>\n",
       "      <td>0.080670</td>\n",
       "      <td>0.033435</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.304077</td>\n",
       "      <td>0.444509</td>\n",
       "      <td>0.304077</td>\n",
       "      <td>0.318972</td>\n",
       "      <td>0.121578</td>\n",
       "      <td>0.104298</td>\n",
       "      <td>0.194425</td>\n",
       "      <td>0.095327</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.704956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   val_name   avg_accuracy   precision    recall   f1 score   mean iou  \\\n",
       "0         0       0.109436    0.403108  0.109436   0.078118   0.039587   \n",
       "1         1       0.304077    0.444509  0.304077   0.318972   0.121578   \n",
       "\n",
       "    Estrato_1   Estrato_2   Estrato_3   Estrato_4   Estrato_5   Estrato_6  \\\n",
       "0    0.082335    0.251546    0.080670    0.033435         1.0         1.0   \n",
       "1    0.104298    0.194425    0.095327    1.000000         1.0         1.0   \n",
       "\n",
       "    No_Definido  \n",
       "0      0.611111  \n",
       "1      0.704956  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_val =  pd.read_csv(PATH_PRUEBAS.replace(\"#\",ZOOM)+\"/prueba_\"+str(pruebas[\"PRUEBA\"][0])+\"/Val/val_scores.csv\")\n",
    "resultados_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./Pruebas/OVERLAECOBO_13/prueba_1/test.txt'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = PATH_PRUEBAS.replace(\"#\",ZOOM)+\"/prueba_\"+str(pruebas[\"PRUEBA\"][0])+\"/test.txt\"\n",
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Archivo test generado: [Test File](./Pruebas/OVERLAECOBO_13/prueba_1/test.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZOOMS = [\"14_COMPOUND\"]\n",
    "for i in ZOOMS:\n",
    "    for j in pruebas[\"PRUEBA\"]:\n",
    "        shutil.copyfile(\"./Pruebas/.gitignore\", PATH_PRUEBAS.replace(\"#\",i)+\"/prueba_\"+str(pruebas[\"PRUEBA\"][j-1])+\"/Val/.gitignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
